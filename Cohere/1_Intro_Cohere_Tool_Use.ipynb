{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "cohere_api_key = os.getenv('COHERE_API_KEY', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Run this cell if you want to make your display wider\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\heena\\Desktop\\Genetative_AI\\genai_env\\Lib\\site-packages\\pydantic\\_internal\\_config.py:341: UserWarning: Valid config keys have changed in V2:\n",
      "* 'allow_population_by_field_name' has been renamed to 'populate_by_name'\n",
      "* 'smart_union' has been removed\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "co = cohere.Client(api_key=cohere_api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Create the Tool\n",
    "- A tool can be any function or service that can receive and send data. \n",
    "- It could be an email service, an SQL database, a vector database, a weather data service, a sports data service, a web search engine, or even another LLM.\n",
    "- Here we will use the example of a dummy database containing only 3 entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daily_sales_report(day: str) -> dict:\n",
    "    \"\"\"\n",
    "    Function to retrieve the sales report for the given day\n",
    "    \"\"\"\n",
    "    # Mock database containing daily sales reports\n",
    "    sales_database = {\n",
    "    '2023-09-28': {'total_sales_amount': 5000,'total_units_sold': 100},\n",
    "    '2023-09-29': {'total_sales_amount': 10000,'total_units_sold': 250},\n",
    "    '2023-09-30': {'total_sales_amount': 8000,'total_units_sold': 200}\n",
    "    }\n",
    "    \n",
    "    report = sales_database.get(day, {})\n",
    "    \n",
    "    if report:\n",
    "        return {\n",
    "            'date': day,\n",
    "            'summary': f\"Total Sales Amount: {report['total_sales_amount']}, Total Units Sold: {report['total_units_sold']}\"\n",
    "        }\n",
    "    else:\n",
    "        return {'date': day, 'summary': 'No sales data available for this day.'}\n",
    "    \n",
    "\n",
    "functions_map = {\n",
    "    \"daily_sales_report\": daily_sales_report\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2 - Define Tool Schema\n",
    "- After defining the tool, next we define the tool schema, which is a description of what the tool does and what are the parameters it takes.\n",
    "- The schema must contain the following fields:\n",
    "    - `name`: the name of the tool.\n",
    "    - `description`: a description of what the tool is and what it is used for.\n",
    "    - `parameter_definitions`: a list of parameters that the tool accepts. For each parameter, we need to define the following fields:\n",
    "        - `description` details about the parameter\n",
    "        - `type` the parameter’s data type, e.g., str, int, and so on\n",
    "        - `required` (either True or False) fields\n",
    "- This schema informs the LLM about what the tool does, and the LLM decides whether to use a particular tool based on it.\n",
    "- Therefore, the more descriptive and specific the schema, the more likely the LLM will make right tool call decisions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"name\": \"daily_sales_report\",\n",
    "        \"description\": \"Connects to a database to retrieve overall sales volumes and sales information for a given day.\",\n",
    "        \"parameter_definitions\": {\n",
    "            \"day\": {\n",
    "                \"description\": \"Retrieves sales data for this day, formatted as YYYY-MM-DD.\",\n",
    "                \"type\": \"str\",\n",
    "                \"required\": True\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 Create Custom Preamble (Optional)\n",
    "- It’s a completely optional step, though it’s likely needed if we want to create a robust and reliable application. \n",
    "- Also note that the preamble is not related to the tool setup, rather it’s part of the instruction to the LLM.\n",
    "- **Preamble Guide**: https://docs.cohere.com/docs/preambles?ref=cohere-ai.ghost.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "preamble = \"\"\"## Task & Context\n",
    "You help people answer their questions and other requests interactively. You will be asked a very wide array of requests on all kinds of topics. You will be equipped with a wide range of search engines or similar tools to help you, which you use to research your answer. You should focus on serving the user's needs as best you can, which will be wide-ranging.\n",
    "\n",
    "## Style Guide\n",
    "Unless the user asks for a different style of answer, you should answer in full sentences, using proper grammar and spelling.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 Running the tool workflow\n",
    "- The tool workflow mainly consists for following four components:\n",
    "    - The user\n",
    "    - The application\n",
    "    - The LLM\n",
    "    - The tools\n",
    "\n",
    "- At its most basic, these four components interact in a workflow through four steps:\n",
    "    - Step 1: Get user message. The LLM gets the user message (via the application).\n",
    "    - Step 2: Generate tool calls. The LLM decides which tools to call (if any) and generates the tool calls.\n",
    "    - Step 3: Get tool results. The application executes the tools, and the results are sent to the LLM.\n",
    "    - Step 4: Generate response and citations. The LLM generates the response and citations back to the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. The application receives the user message\n",
    "message = \"Can you provide a sales summary for 29th September 2023?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"command-r-plus\"\n",
    "\n",
    "# Initial response to the user message\n",
    "response = co.chat(\n",
    "    message=message,\n",
    "    model=model,\n",
    "    preamble=preamble,\n",
    "    tools=tools,\n",
    "    force_single_step=True\n",
    ")\n",
    "tool_calls = response.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolCall(name='daily_sales_report', parameters={'day': '2023-09-29'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool calls:\n",
      "\n",
      "#1\n",
      "Tool: daily_sales_report\n",
      "Parameters: {'day': '2023-09-29'}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Tool calls:\\n\")\n",
    "for i, t in enumerate(tool_calls):\n",
    "    print(f\"#{i+1}\\nTool: {t.name}\\nParameters: {t.parameters}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = response.chat_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now call the function for the tool selected by the LLM\n",
    "tool_results = []\n",
    "for tc in tool_calls:\n",
    "    tool_output = functions_map[tc.name](**tc.parameters)\n",
    "    tool_call = {\"name\": tc.name, \"parameters\": tc.parameters}\n",
    "    tool_results.append({\"call\": tool_call, \"outputs\": [tool_output]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'call': {'name': 'daily_sales_report', 'parameters': {'day': '2023-09-29'}},\n",
       "  'outputs': [{'date': '2023-09-29',\n",
       "    'summary': 'Total Sales Amount: 10000, Total Units Sold: 250'}]}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final response:\n",
      "On 29 September 2023, the total sales amount was 10,000 and the total units sold was 250.\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# Send the generated results to the LLM and generate response for the user\n",
    "# Generate response\n",
    "final_response = co.chat(\n",
    "    message=\"\",\n",
    "    model=model,\n",
    "    preamble=preamble,\n",
    "    tools=tools,\n",
    "    tool_results=tool_results,\n",
    "    chat_history=response.chat_history\n",
    ")\n",
    "    \n",
    "print(\"Final response:\")\n",
    "print(final_response.text)\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Citations:\n",
      "start=26 end=55 text='total sales amount was 10,000' document_ids=['daily_sales_report:0:2:0']\n",
      "start=64 end=88 text='total units sold was 250' document_ids=['daily_sales_report:0:2:0']\n",
      "\n",
      "Cited Documents:\n",
      "{'date': '2023-09-29', 'id': 'daily_sales_report:0:2:0', 'summary': 'Total Sales Amount: 10000, Total Units Sold: 250', 'tool_name': 'daily_sales_report'}\n"
     ]
    }
   ],
   "source": [
    "# get the citations\n",
    "if final_response.citations:\n",
    "    print(\"\\nCitations:\")\n",
    "    for citation in final_response.citations:\n",
    "        print(citation)\n",
    "    print(\"\\nCited Documents:\")\n",
    "    for document in final_response.documents:\n",
    "        print(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool Use Modes\n",
    "- A good tool use API must be able to handle different scenarios, from simple to complex LLM tool calls. \n",
    "- This translates to being able to call tools in different modes: single-step, multi-step, and parallel.\n",
    "- For details Refer - https://cohere.com/llmu/tool-use-anatomy?ref=cohere-ai.ghost.io"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
