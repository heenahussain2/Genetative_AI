{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro Large Language Model\n",
    "- A large language model is basically just two files, in a hypothetical directory. The files are parameters and a run file that contains the code that runs those parameters.\n",
    "- The parameters are the weights of the neural network that is the language model. Each parameter is stored as 2 bytes (because it is float 16 data type). So if a model (llama-2-70b) has 70 billion parameters, the file will be  about 140 GB in size.\n",
    "- We also need something that runs the neural network. This piece of code is implemented in the run file. This file can be in any language (C, python ..).\n",
    "- The C file contains only ~500 lines of code with no other dependencies to implement the neural network architecture "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
